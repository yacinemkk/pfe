{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6AC6YBdXOpS"
      },
      "source": [
        "# IoT Device Identification with Adversarial Training\n",
        "\n",
        "This notebook runs the adversarial training pipeline on Google Colab with GPU support.\n",
        "\n",
        "**Features:**\n",
        "- Automatic GPU detection\n",
        "- Google Drive integration for saving results\n",
        "- Clone from GitHub repository\n",
        "- Run adversarial training experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRlMjBKmXOpV"
      },
      "source": [
        "## 1. Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZG1S5XGRXOpW",
        "outputId": "de0e70f6-f368-4965-f2aa-a3812ac1415a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qPJ8pLjeXOpW",
        "outputId": "59e2c1a7-4005-4542-b39e-e4ad43856924",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/pfe'...\n",
            "remote: Enumerating objects: 59, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 59 (delta 16), reused 53 (delta 10), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (59/59), 2.42 MiB | 8.63 MiB/s, done.\n",
            "Resolving deltas: 100% (16/16), done.\n",
            "/content/pfe\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/yacinemkk/pfe.git /content/pfe\n",
        "%cd /content/pfe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2ojycNDoXOpX"
      },
      "outputs": [],
      "source": [
        "!pip install torch scikit-learn pandas numpy tqdm -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "buIISxC2XOpY",
        "outputId": "67d743d0-107f-4c3b-d02d-034c1ef3f50b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.10.0+cu128\n",
            "CUDA available: True\n",
            "CUDA device: NVIDIA L4\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/pfe')\n",
        "\n",
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeXIksUnXOpY"
      },
      "source": [
        "## 2. Configure Paths for Google Drive\n",
        "\n",
        "Results will be saved to your Google Drive under `/content/drive/MyDrive/pfe_results/`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ov_EHh6AXOpZ",
        "outputId": "db8ec69b-0620-40b1-b86c-1b805ea25a21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results will be saved to: /content/drive/MyDrive/pfe_results/models\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import config.config as config\n",
        "\n",
        "GDRIVE_BASE = Path('/content/drive/MyDrive/pfe_results')\n",
        "GDRIVE_BASE.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "config.RESULTS_DIR = GDRIVE_BASE / 'models'\n",
        "config.RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Results will be saved to: {config.RESULTS_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnqpX2qlXOpZ"
      },
      "source": [
        "## 3. Data Setup\n",
        "\n",
        "Upload your data to Google Drive or use the data in the repository.\n",
        "\n",
        "Option A: Data already in repo under `data/` folder\n",
        "Option B: Upload data to Google Drive and set path below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mc2ScJoFXOpa",
        "outputId": "573c91d5-7c6a-4923-8872-4524763425e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using data from: /content/drive/MyDrive/PFE/IPFIX_ML_Instances\n",
            "Found 12 labeled data files\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Data is already in Google Drive at PFE/IPFIX_ML_Instances\n",
        "GDRIVE_DATA = Path('/content/drive/MyDrive/PFE')\n",
        "config.RAW_DATA_DIR = GDRIVE_DATA / 'IPFIX_ML_Instances'\n",
        "config.PROCESSED_DATA_DIR = GDRIVE_DATA / 'processed'\n",
        "\n",
        "print(f\"Using data from: {config.RAW_DATA_DIR}\")\n",
        "if config.RAW_DATA_DIR.exists():\n",
        "    print(f\"Found {len(list(config.RAW_DATA_DIR.glob('home*_labeled.csv')))} labeled data files\")\n",
        "else:\n",
        "    print(\"WARNING: Data directory not found!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJfCtiQoXOpb"
      },
      "source": [
        "## 4. Run Adversarial Training\n",
        "\n",
        "Configure and run the training experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-rMiMXXlXOpb"
      },
      "outputs": [],
      "source": [
        "from train_adversarial import run_experiment, compare_models\n",
        "\n",
        "MODEL_TYPE = 'lstm'          # Options: 'lstm', 'transformer', 'cnn_lstm', 'cnn'\n",
        "SEQ_LENGTH = 10              # Sequence length (try 10, 25, or 50)\n",
        "ADV_METHOD = 'hybrid'        # Options: 'none', 'feature', 'pgd', 'fgsm', 'hybrid'\n",
        "ADV_RATIO = 0.2              # Ratio of adversarial samples (0.0 - 1.0)\n",
        "EPOCHS = 30                  # Number of training epochs\n",
        "BATCH_SIZE = 64              # Batch size\n",
        "MAX_FILES = None             # Limit data files (None for all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZFWflkW9XOpb",
        "outputId": "ee9d72f3-8f36-4b28-8fa6-dd24cb12acb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 883
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Experiment: LSTM | Seq=10 | Adv=hybrid\n",
            "Device: cuda\n",
            "============================================================\n",
            "\n",
            "Loading data with sequence length=10, stride=5\n",
            "  Loading home10_labeled.csv...\n",
            "  Loading home11_labeled.csv...\n",
            "  Loading home12_labeled.csv...\n",
            "  Loading home1_labeled.csv...\n",
            "  Loading home2_labeled.csv...\n",
            "  Loading home3_labeled.csv...\n",
            "  Loading home4_labeled.csv...\n",
            "  Loading home5_labeled.csv...\n",
            "  Loading home6_labeled.csv...\n",
            "  Loading home7_labeled.csv...\n",
            "  Loading home8_labeled.csv...\n",
            "  Loading home9_labeled.csv...\n",
            "  Samples: 18,016,193 | Classes: 23\n",
            "  Creating sequences...\n",
            "  Total sequences: 3,603,222\n",
            "  Train: 2,882,577 | Val: 360,322 | Test: 360,323\n",
            "\n",
            "Input size: 37, Classes: 23\n",
            "\n",
            "Model parameters: 602,135\n",
            "\n",
            "Training with adversarial ratio: 0.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "cudnn RNN backward can only be called in training mode",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1984704904.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m results = run_experiment(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODEL_TYPE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mseq_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSEQ_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0madv_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mADV_METHOD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0madv_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mADV_RATIO\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/pfe/train_adversarial.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(model_type, seq_length, adv_method, adv_ratio, epochs, batch_size, max_files, save_results)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nTraining with adversarial ratio: {adv_ratio}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m     history = trainer.fit(\n\u001b[0m\u001b[1;32m    480\u001b[0m         \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/pfe/train_adversarial.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_loader, val_loader, epochs, lr, weight_decay, adv_generator, adv_ratio, adv_method, save_path, early_stopping_patience)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             train_loss, train_acc = self.train_epoch(\n\u001b[0m\u001b[1;32m    326\u001b[0m                 \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             )\n",
            "\u001b[0;32m/content/pfe/train_adversarial.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, train_loader, optimizer, criterion, adv_generator, adv_ratio, adv_method)\u001b[0m\n\u001b[1;32m    226\u001b[0m                     \u001b[0madv_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_adv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                     X_adv = adv_generator.sequence_attack.generate_batch(\n\u001b[0m\u001b[1;32m    229\u001b[0m                         \u001b[0mX_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0madv_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                         \u001b[0my_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0madv_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/pfe/src/adversarial/attacks.py\u001b[0m in \u001b[0;36mgenerate_batch\u001b[0;34m(self, X, y, batch_size, method, verbose)\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m             \u001b[0mX_batch_adv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m             \u001b[0mX_adv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch_adv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/pfe/src/adversarial/attacks.py\u001b[0m in \u001b[0;36mpgd_attack\u001b[0;34m(self, X, y, targeted, target_class)\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_adv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m             )\n\u001b[0;32m--> 630\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    866\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cudnn RNN backward can only be called in training mode"
          ]
        }
      ],
      "source": [
        "results = run_experiment(\n",
        "    model_type=MODEL_TYPE,\n",
        "    seq_length=SEQ_LENGTH,\n",
        "    adv_method=ADV_METHOD,\n",
        "    adv_ratio=ADV_RATIO,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    max_files=MAX_FILES,\n",
        "    save_results=True\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Test Accuracy (Clean): {results['test_accuracy_clean']:.4f}\")\n",
        "if 'adversarial_results' in results:\n",
        "    print(\"\\nAdversarial Robustness:\")\n",
        "    for attack, metrics in results['adversarial_results'].items():\n",
        "        print(f\"  {attack}: {metrics['accuracy']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAC0pvUbXOpc"
      },
      "source": [
        "## 5. Run Full Comparison (Optional)\n",
        "\n",
        "Compare all models, sequence lengths, and adversarial methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCohi40_XOpc"
      },
      "outputs": [],
      "source": [
        "RUN_COMPARISON = False  # Set to True to run full comparison\n",
        "\n",
        "if RUN_COMPARISON:\n",
        "    comparison_results = compare_models(\n",
        "        seq_lengths=[10, 25],\n",
        "        models=['lstm', 'transformer'],\n",
        "        adv_methods=['none', 'pgd', 'hybrid'],\n",
        "        epochs=20,\n",
        "        max_files=None\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldyUCGNlXOpc"
      },
      "source": [
        "## 6. Save Final Results to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdvKRaVFXOpc"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "final_results = {\n",
        "    'timestamp': datetime.now().isoformat(),\n",
        "    'experiment': results\n",
        "}\n",
        "\n",
        "results_file = GDRIVE_BASE / f\"final_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "with open(results_file, 'w') as f:\n",
        "    json.dump(final_results, f, indent=2, default=str)\n",
        "\n",
        "print(f\"Results saved to: {results_file}\")\n",
        "print(\"\\nAll done! Check your Google Drive for saved models and results.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}